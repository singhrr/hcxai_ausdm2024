# Tutorial on Human-Centred Explainable AI: Principles, Guidelines, and Practical Examples

## Abstract
This tutorial on Human-Centred Explainable AI (HCXAI) aims to equip participants with the knowledge and skills necessary to develop explainable AI systems. Through a human-centred approach, participants will explore core principles such as user understanding, trust calibration, and cognitive engagement. The session will cover a variety of explanation methods, offering guidance on designing effective explanations that enhance user understanding and interaction with AI systems. Attendees will gain insights into best practices for conducting user studies and evaluating XAI systems. Through interactive demonstrations and hands-on activities, they will deepen their practical knowledge. Participants will also receive support materials, including slides, links and references to XAI tools, and examples of user studies.

## Objectives
- Understand the core principles and importance of Explainable AI (XAI) and Human-Centred approaches.
- Learn about different explanation types and how to design effective explanations that enhance user understanding and trust.
- Gain insights into techniques that support human-AI collaborative decision-making.
- Learn to design and conduct user studies to evaluate the effectiveness of XAI systems.

## Agenda
For a detailed agenda, visit the [AusDM Tutorial Day 1 page](https://ausdm24.ausdm.org/Tutorial-Day1.html).

| **Item**                       | **Time**      | **Activities**                                                                                                                                                     |
|--------------------------------|---------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Introduction                   | 20 minutes    | - Welcome and Objectives <br> - Overview of Explainable AI (XAI) <br> - Introduction to Human-Centred XAI (HCXAI)                                                 |
| Overview of HCXAI              | 40 minutes    | - Key Concepts of HCXAI: Understanding, Trust, Usability, and Human-AI Collaboration                                        |
| Explanation Methods            | 30 minutes    | - Types of Explanations: Local vs. Global, Model-agnostic vs. Model-specific <br> - Feature-based, Example-based, Concept-based explanations |
| **Break**                      | 10 minutes    |                                                                                                                              |
| Designing Effective Explanations | 40 minutes | - Increasing User Control and Engagement <br> - Avoiding Over-reliance and Under-reliance on AI predictions                   |
| User Studies in XAI            | 30 minutes    | - Designing and Conducting User Studies <br> - Evaluation Metrics: User Understanding, Trust Calibration, Cognitive Load, and Task Performance |
| Conclusion and Q&A             | 20 minutes    | - Summary of Key Concepts <br> - Open Discussion and Q&A <br> - Future Trends: Explainability for LLMs and ethical considerations |


## Organisers


| **Dr. Ronal Singh**                                                                                               | **Prof Tim Miller**                                                                                               |
|--------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|
| ![Dr. Ronal Singh](organisation/images/ronal.jpg) <br> **Dr. Ronal Singh** <br> Research Scientist <br> Human-Centric Security & CINTEL FSP @ CSIRO | ![Prof Tim Miller](organisation/images/tim.png) <br> **Prof Tim Miller** <br> Professor of AI <br> School of Electrical Engineering and Computer Science @ The University of Queensland |
---

## Organisers
<table>
  <tr>
    <td align="center">
      <img src="organisation/images/ronal.jpg" width="100" height="100" alt="Dr. Jane Doe"><br>
      <strong>Dr. Ronal Singh</strong><br>
       Research Scientist<br>
      Human-Centric Security & CINTEL FSP @ CSIRO's Data61
    </td>
    <td align="center">
      <img src="organisation/images/tim.png" width="100" height="100" alt="Dr. John Smith"><br>
      <strong>Prof Tim Miller</strong><br>
      Professor of AI<br>
      School of Electrical Engineering and Computer Science @ The University of Queensland
    </td>
  </tr>
</table>

For more details, please refer to the [official AusDM Tutorial Day 1 page](https://ausdm24.ausdm.org/Tutorial-Day1.html).



Ronal is a Research Scientist with the Human Centric Security team in CSIRO's Data61 and a member of the CINTEL FSP. Ronal's primary interest lies in artificial intelligence, particularly multi-modal human-agent interactions, AI-assisted decision-making, explainable AI, intention recognition, and multiagent communication planning. Previously, he was a Research Fellow in Human-Agent Collaboration and an Associate Lecturer in the School of Computing and Information Systems at the University of Melbourne. Ronal completed his PhD in 2018 from the University of Melbourne and his BSc and MSc degrees in Computer Science from the University of the South Pacific in the Fiji Islands.
Website: https://people.csiro.au/s/r/ronal-singh

Tim is a Professor of Artificial Intelligence in the School of Electrical Engineering and Computer Science at The University of Queensland, Meaanjin/Brisbane, Australia. His research draws on machine learning, reinforcement learning, AI planning, interaction design, and cognitive science, to help people to make better decisions. He has done work on areas including explainable AI, human-AI planning, and human-centered decision support. Prior to his appointment at The University of Queensland, Tim was a Professor of Computer Science in the School of Computing and Information Systems at The University of Melbourne, where he was founding co-director of The Centre for AI and Digital Ethics. He is an honorary professor at the University of Melbourne.
Website: https://about.uq.edu.au/experts/41328